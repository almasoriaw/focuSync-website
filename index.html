<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>focuSync - AI-Powered Focus Detection</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="logo-container">
                <img src="assets/logo.png" alt="focuSync Logo" class="logo">
                <h1>focuSync</h1>
            </div>
            <nav>
                <ul>
                    <li><a href="index.html" class="active">Home</a></li>
                    <li><a href="science.html">The Science</a></li>
                    <li><a href="methodology.html">Methodology</a></li>
                    <li><a href="implementation.html">Implementation</a></li>
                    <li><a href="ethics.html">Ethics</a></li>
                    <li><a href="references.html">References</a></li>
                </ul>
            </nav>
        </div>
    </header>

    <section class="hero">
        <div class="container">
            <h2>Behavioral Science-Informed Focus Detection</h2>
            <p>focuSync is an adaptive AI-powered tool that promotes digital wellbeing by delivering real-time, personalized focus support based on each userâ€™s unique attention patterns.</p>
            <p>focuSync uses OpenFace 3.0 and LSTM neural networks to detect user focus states based on eye-tracking and facial expressions.</p>
            <div class="cta-buttons">
                <a href="science.html" class="btn">Learn the Science</a>
                <a href="methodology.html" class="btn">Explore Methodology</a>
            </div>
        </div>
    </section>

    <section class="features">
        <div class="container">
            <h2>Key Features</h2>
            <div class="feature-grid">
                <div class="feature">
                    <h3>98% Accuracy on Custom Self-Made Dataset</h3>
                    <p>LSTM Focus Classifier trained on video data that was collected from our team self-made videos, hand-labeled by our team.</p>
                </div>
                <div class="feature">
                    <h3>Research-Backed</h3>
                    <p>Built on behavioural and neuroscience research and comprehensive eye-tracking and facial expression studies</p>
                </div>
                <div class="feature">
                    <h3>Action Unit Analysis</h3>
                    <p>Leverages facial action units to identify focus and engagement patterns</p>
                </div>
                <div class="feature">
                    <h3>Ethical Development</h3>
                    <p>Created with user interviews and ethical AI considerations at the forefront</p>
                </div>
            </div>
        </div>
    </section>

    <section class="demo">
        <div class="container">
            <h2>See focuSync in Action</h2>
            <p>Watch our technology detect focus states in real-time</p>
            
            <div class="demo-container">
                <!-- Add your demo GIFs here -->
                <div class="demo-item">
                    <div class="demo-placeholder">
                        <img src="assets/gif_demo_focusedexample.gif" alt="Focused State Detection">
                    </div>
                    <p>Focused State Detection</p>
                </div>
                
                <div class="demo-item">
                    <div class="demo-placeholder">
                        <img src="assets/gif_demo_distractedexample.gif" alt="Distracted State Detection">
                    </div>
                    <p>Distracted State Detection</p>
                </div>
            </div>
        </div>
    </section>

    <section class="overview">
        <div class="container">
            <h2>Project Overview</h2>
            <p>focuSync represents a breakthrough in attention monitoring technology. By combining OpenFace 3.0's sophisticated facial analysis with custom LSTM neural networks, we've created a system that can accurately identify when users are in states of focus.</p>
            
            <p>In future work, focuSync will continue to leverage neuroplasticity research, so our system recognizes the biological markers of attention and learning readiness. This makes focuSync not just a technical achievement, but a practical application of cutting-edge neuroscience.</p>
            
            <div class="stats">
                <div class="stat">
                    <h3>98%</h3>
                    <p>Focus Detection Accuracy Self-Made Dataset</p>
                </div>
                <div class="stat">
                    <h3>8</h3>
                    <p>Key Action Units Analyzed</p>
                </div>
                <div class="stat">
                    <h3>100+</h3>
                    <p>Research Hours</p>
                </div>
            </div>
        </div>
    </section>

    <footer>
        <div class="container">
            <p>&copy; 2025 focuSync Project. All rights reserved.</p>
        </div>
    </footer>
</body>
</html>
