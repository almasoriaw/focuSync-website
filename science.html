<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>focuSync - The Science Behind Focus</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="logo-container">
                <img src="assets/logo_nobg.png" alt="focuSync Logo" class="logo">
                <h1>focuSync</h1>
            </div>
            <nav>
                <ul>
                    <li><a href="index.html">Home</a></li>
                    <li><a href="science.html" class="active">The Science</a></li>
                    <li><a href="methodology.html">Methodology</a></li>
                    <li><a href="implementation.html">Implementation</a></li>
                    <li><a href="ethics.html">Ethics</a></li>
                    <li><a href="references.html">References</a></li>
                    <li><a href="thank-you.html">Thank You</a></li>
                </ul>
            </nav>
        </div>
    </header>

    <section class="hero">
        <div class="container">
            <h2>The Science Behind Focus</h2>
            <p>Facial and gaze-based attention detection in real-world knowledge work</p>
        </div>
    </section>

    <section class="page-content">
        <div class="container">
            <h2>Behavioral Model of Focus</h2>
            <p>Our system builds on empirical findings from the CHI 2020 study <em>Faces of Focus</em>, which investigated how facial expressions and gaze patterns correlate with self-reported attentional states among researchers in naturalistic settings. Using a framework by Mark et al., focus is defined as a state where users are both <strong>highly engaged</strong> and <strong>experiencing cognitive challenge</strong>.</p>

            <h2>Facial Markers of Attention</h2>
            <p>OpenFace 3.0 allows us to extract key behavioral cues in real time. The following Action Units (AUs) and facial metrics are significantly associated with attention states:</p>

            <table style="width:100%; border-collapse: collapse; margin: 30px 0;">
                <tr style="background-color: #2c5aa0; color: white;">
                    <th style="padding: 12px; text-align: left; border: 1px solid #ddd;">Focus State</th>
                    <th style="padding: 12px; text-align: left; border: 1px solid #ddd;">Associated Facial Cues</th>
                    <th style="padding: 12px; text-align: left; border: 1px solid #ddd;">Correlation</th>
                </tr>
                <tr>
                    <td style="padding: 12px; border: 1px solid #ddd;">Engagement</td>
                    <td style="padding: 12px; border: 1px solid #ddd;">AU20 (Lip Stretcher), AU25 (Lips Part)</td>
                    <td style="padding: 12px; border: 1px solid #ddd;">Positive</td>
                </tr>
                <tr>
                    <td style="padding: 12px; border: 1px solid #ddd;">Engagement</td>
                    <td style="padding: 12px; border: 1px solid #ddd;">Pitch (head tilt), Gaze Angle, AU14 (Dimpler)</td>
                    <td style="padding: 12px; border: 1px solid #ddd;">Negative</td>
                </tr>
                <tr>
                    <td style="padding: 12px; border: 1px solid #ddd;">Challenge</td>
                    <td style="padding: 12px; border: 1px solid #ddd;">AU5 (Upper Lid Raiser)</td>
                    <td style="padding: 12px; border: 1px solid #ddd;">Positive</td>
                </tr>
                <tr>
                    <td style="padding: 12px; border: 1px solid #ddd;">Challenge</td>
                    <td style="padding: 12px; border: 1px solid #ddd;">Gaze Angle Movement, AU28 (Lip Suck)</td>
                    <td style="padding: 12px; border: 1px solid #ddd;">Negative</td>
                </tr>
                <tr>
                    <td style="padding: 12px; border: 1px solid #ddd;">Focus (High Engagement & Challenge)</td>
                    <td style="padding: 12px; border: 1px solid #ddd;">AU1 (Inner Brow Raiser), AU2 (Outer Brow Raiser), AU12 (Lip Corner Puller), AU20 (Lip Stretcher)</td>
                    <td style="padding: 12px; border: 1px solid #ddd;">Significant Effect</td>
                </tr>
            </table>

            <h2>Gaze & Head Pose</h2>
            <p>Focus is also indicated by consistent gaze direction, reduced gaze shifts, and changes in head pose. For example:</p>
            <ul>
                <li>Focused users tend to show lower average pitch (less head movement) and more screen-oriented gaze.</li>
                <li>Challenged users display fewer saccadic gaze shifts and longer fixations, indicating deeper information processing.</li>
                <li>Head distance and posture (Z-axis) also vary between rote and focused states.</li>
            </ul>

            <h2>Our Contribution</h2>
            <p>focuSync integrates validated facial and gaze indicators into a lightweight attention detection framework. Unlike apps that simply block distractions, our approach is fully vision-based and works in everyday settings using just a webcam. By using facial action units and eye-tracking as proxies for more complex signals like EEG, we make real-time focus tracking more accessible and scalable. In future phases, we plan to expand and incorporate additional data sources such as EEG, heart rate, and other physiological signals to further enhance accuracy.</p>
        </div>
    </section>

    <footer>
        <div class="container">
            <p>&copy; 2025 focuSync Project. All rights reserved.</p>
        </div>
    </footer>
</body>
</html>
